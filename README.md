# Goals

## Long term
* Hypothesis: Interesting things happen when there is a medium amount of entropy. Too much entropy, we can't make sense of it. Too much predictability and it is boring.
* You can measure the entropy of music, at the level of a song, or at any moment in a song.
* Are there patterns in the amount of entropy in a song?
* Does entropy relate to how good a song is?
* Can a machine learn the interaction between entropy and music, and generate good music with that model?
* Model music while giving it very little preconception of what music is.

### done

## Medium term
* Learn about recurrent neural networks and the associated tools.
* Does different training genres produce songs of that genre?

### done

## Short term
* Better process for running the process and save intermediate steps
* Some measure of how good the model is more than a subject measurement of how good the song is
* What kind of hardware requirements do we have?
* adapt charRNN to work with this

### done

## Today
* get a baseline with a simple ML algorithm

### done
* read RNN article
* Decide if brain.js is worth continuing

# Notes

the output of a RNN doesn't need to be a note, it can be a sequence of notes, or maybe a whole song?
brain.js is not worth pursuing
